# Large Language Model (LLM) from scratch using Python

### Acknowledgements
I would like to extend my sincere thanks to **[freeCodeCamp](https://www.freecodecamp.org/)** and the creator of the **[tutorial](https://www.youtube.com/watch?si=bKUnRhoGHbYjT5Ay&v=UU1WVnMk4E8&feature=youtu.be)** for their invaluable content and guidance in helping me build this project. This project wouldn't have been possible without their educational resources.

---

<br>
<br>

## Introduction : What is an LLM ? ü§î

Imagine you‚Äôre texting a friend, and they ask :<br>

**"Hey, do you know how to bake banana bread?"**<br>

You pause... baking isn't exactly your strong suit. But instead of admitting defeat, you turn to your trusty LLM (Large Language Model), which instantly gives you the perfect banana bread recipe ‚Äî with tips on how to make it extra fluffy. üçûüçå
<br>
<br>

Crisis averted! Thanks to the LLM, you‚Äôre now the banana bread expert your friend thinks you are.

---

<br>

Well, that's a small funny introduction of one of the use cases of LLMs. Now, let's dive into the technical world of LLMs !
<br>

Large Language Models are the backbone of many advanced AI systems today. They are trained on vast amounts of text data, enabling them to understand, generate, and even engage in meaningful conversations with users. In this project, we'll explore how LLMs work from the ground up, covering everything from tokenization and embeddings to training techniques and model fine-tuning.

<br>

According to **AWS**üîª
> **Large Language Models (LLMs)** are advanced deep learning models pre-trained on massive datasets, typically utilizing the transformer architecture. Transformers consist of an encoder and decoder with self-attention mechanisms, enabling them to understand relationships between words and extract meanings from text sequences. Unlike earlier RNNs that process inputs sequentially, transformers handle entire sequences in parallel, making them more efficient and faster to train using GPUs. Their architecture supports massive models, often with hundreds of billions of parameters, allowing them to ingest vast amounts of data from sources like Common Crawl and Wikipedia, learning grammar, language, and knowledge through self-learning.
